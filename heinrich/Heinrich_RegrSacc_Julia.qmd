---
title: "Nils Wendel Heinrich: Regressive Saccades"
subtitle: "RePsychLing in SMLP2023"
author: "Reinhold Kliegl"
date: "2023-09-08"
format:
  html:
    embed-resources: true
    toc: true
    toc-depth: 2
    code-fold: false
    number-sections: true
    fig-width: 8
    fig-height: 6
editor_options:
  chunk_output_type: console
jupyter: julia-1.9
---

# Description


# Setup

## Packages

```{julia}
#| label: packages

using Arrow
using CairoMakie
using DataFrames
using MixedModels
using MixedModelsMakie

CairoMakie.activate!(; type="svg");
```

## Code book

```{julia}
#| label: data

arrow_path = joinpath(@__DIR__, "data", "Heinrich_RegressiveSaccades.arrow")
dat = DataFrame(Arrow.Table(arrow_path));
describe(dat)
```

# Contrasts

We have only the random factor `Subj` and declare it as a grouping variable.

```{julia}
contrasts = Dict(:Subj => Grouping());
```

# Model selection

## Only varying intercept LMM

```{julia}
#| label: m_ovi

m_ovi = let
    form = @formula(sa ~ 1 + nvo + nvdt + IN + 
                        (1 | Subj))
    fit(MixedModel, form, dat; contrasts)
end
```


## Complex LMM

 We start with a complex LMM; it is not _maximal_ because not all within-subject covariates are terms in RES.

```{julia}
#| label: m_cpx

m_cpx = let
    form = @formula(sa ~ 1 + nvo + nvdt + IN + 
                        (1 + IN | Subj))
    fit(MixedModel, form, dat; contrasts)
end
```

```{julia}
issingular(m_cpx)  # overparameterized
```

```{julia}
VarCorr(m_cpx)
```

This model is overparameterized.

## Zero-correlation parameter LMM

```{julia}
#| label: m_zcp

m_zcp = let
    form = @formula(sa ~ 1 + nvo + nvdt + IN + 
                zerocorr(1 + IN | Subj))
    fit(MixedModel, form, dat; contrasts)
end
```

```{julia}
issingular(m_zcp)  # overparameterized
```

```{julia}
VarCorr(m_zcp)
```

LMM `m_zcp` is still overparameterized. No evidence for reliable VC for `inw`.

# Parsimonious LMM (1)

We remove VC for `inw` with no variance from RES.

```{julia}
#| label: m_prsm1

m_prm1 = let
    form = @formula(sa ~ 1 + nvo + nvdt + inw + ins + 
                zerocorr(1 + ins | Subj))
    fit(MixedModel, form, dat; contrasts)
end
```

```{julia}
issingular(m_prm1)  # ok
```

```{julia}
VarCorr(m_prm1)
```

```{julia}
let mods = [m_ovi, m_prm1, m_zcp, m_cpx]
    DataFrame(;
              model=[:m_ovi, :m_prm1, :m_zcp, :m_cpx],
              pars=dof.(mods),
              geomdof=round.(Int, (sum âˆ˜ leverage).(mods)),
              AIC=round.(Int, aic.(mods)),
              AICc=round.(Int, aicc.(mods)),
              BIC=round.(Int, bic.(mods)))
end
```

AIC: select m_prm1
BIC: select m_ovi

# Parsimonious LMM (2)

We add a CP for `GM` and `ins`.

```{julia}
#| label: m_prm2

m_prm2 = let
    form = @formula(sa ~ 1 + nvo + nvdt + inw + ins + 
                        (1 + ins | Subj))
    fit(MixedModel, form, dat; contrasts)
end
```

```{julia}
issingular(m_prm2)  # ok
```

```{julia}
VarCorr(m_prm2)
```

```{julia}
#| label: compare2
MixedModels.likelihoodratiotest(m_prm1, m_prm2)
```

No improvement in goodness of fit. We stay with `m_prm1.`

# Figures

## Caterpillar plot

```{julia}
#| fig-cap1: Prediction intervals on subject random effects for model m_prm1
#| label: fig-cm_prm1
#|
re_info = ranefinfo(m_prm1)
caterpillar!(Figure(; resolution=(800, 1200)), re_info[:Subj]; orderby=1)
```

## Shrinkage plot

```{julia}
#| code-fold: true
#| label: fig-shrinkage
#|
#| fig-cap: Shrinkage plots of the subject random effects in model m_prsm2
shrinkageplot(m_prm1)
```

# Appendix
```{julia}
versioninfo()
```
